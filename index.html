<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rafael Nadalin's Portfolio</title>
    <link rel="icon" href="./favicon.png" type="image/png">
    <link rel="stylesheet"
        href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
    <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.css">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header class="bg-dark text-white py-3">
        <nav class="navbar navbar-expand-lg navbar-light">
            <a class="navbar-brand" href="#"><img src="logo-w.png" width="120"
                    alt="Logo" style="hover:opacity 70%"></a>
            <button class="navbar-toggler" type="button" data-toggle="collapse"
                data-target="#navbarNav" aria-controls="navbarNav"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item"><a class="nav-link"
                            href="#projects">Projects</a></li>
                    <li class="nav-item"><a class="nav-link"
                            href="#experience">Experience</a></li>
                    <li class="nav-item"><a class="nav-link"
                            href="#contact">Contact</a></li>
                </ul>
            </div>
        </nav>
    </header>
    <div class="container fade-in" data-aos="fade-up">
        <div class="about">
            <p>Hello, I'm Rafael Nadalin, 22 years old, graduated in Systems Analysis and Development and this is my</p>
            <h1>DATA ENGINEERING PORTFOLIO</h1>
            <div class="skills">
                <span>Python</span>
                <span>SQL</span>
                <span>GCP</span>
                <span>PySpark</span>
                <span>MongoDB</span>
                <span>Pandas</span>
                <span>Docker</span>
                <a href="https://www.linkedin.com/in/rafael-nadalin-68166722a/"><img
                        src="linkedin-logo.png" alt="LinkedIn" class="icon"
                        width="60px"></a>
                <a href="https://github.com/Tudolin"><img src="git-logo.png"
                        alt="GitHub" class="icon" width="60px"></a>
            </div>
        </div>
        <section id="projects" class="section projects" data-aos="fade-up">
            <h2 class="section-title">Projects <span>.</span></h2>
        
            <div class="project" data-aos="fade-up">
                <div class="project-info">
                    <h3 class="project-title">ETL - Redesim Web Scraping</h3>
                    <p> 
                        <strong>Introduction:</strong>
                        <br><br> 
                        This project automates data extraction from the Redesim website, monitoring license protocol statuses. The application uses Firebase to store results and send email notifications when changes occur.
                        <br><br> 
                        <strong>Project Goal:</strong>
                        <br><br> 
                        The main objective is to perform automated data extraction and processing through web scraping, along with sending automatic update alerts.
                        <br><br> 
                        <strong>Development Process:</strong>
                        <br><br> 
                        The main challenges were configuring the scraping using `BeautifulSoup` and `requests` to access Redesim data and implementing email notifications with `smtplib`. Firebase integration enabled efficient data storage. Technologies used: Python, Firebase, Google Cloud Platform, Web Scraping (BeautifulSoup and Requests), SMTP.
                        <br><br> 
                        <strong>Conclusion:</strong>
                        <br><br> 
                        The project enhanced my skills in automation with web scraping and API integration. Future plans include implementing Airflow for cloud scheduling and adding Docker containers.
                    </p>
                    <a href="https://github.com/Tudolin/WebScrapingRedesim" target="_blank" class="project-link">View Code</a>
                </div>
            </div>
        
            <div class="project" data-aos="fade-up">
                <div class="project-info">
                    <h3 class="project-title">ETL - YouTube Data Pipeline</h3>
                    <p>
                        <strong>Introduction:</strong>
                        <br><br> 
                        This project performs extraction, transformation, and loading of data from YouTube channels using YouTube Analytics API and Google Cloud Console.
                        <br><br> 
                        <strong>Project Goal:</strong>
                        <br><br> 
                        The focus was practicing API requests, authentication methods, and building an ETL pipeline.
                        <br><br> 
                        <strong>Development Process:</strong>
                        <br><br> 
                        Challenges included creating an authentication flow with YouTube Analytics API and building the data extraction and standardization pipeline. Technologies used: Python, GCP, YouTube Analytics API, Object-Oriented Programming, and RestAPI.
                        <br><br> 
                        <strong>Conclusion:</strong>
                        <br><br> 
                        I gained deeper understanding of OAuth2 authentication and API report extraction. Future plans include adding Airflow for cloud automation.
                    </p>
                    <a href="https://github.com/Tudolin/gcp-pipeline" target="_blank" class="project-link">View Code</a>
                </div>
            </div>
        
            <div class="project" data-aos="fade-up">
                <div class="project-info">
                    <h3 class="project-title">ETL - Checklist FÃ¡cil</h3>
                    <p> 
                        <strong>Introduction:</strong>
                        <br><br> 
                        This ETL extracts information from Checklist FÃ¡cil API, focusing on performance and non-compliance recurrence.
                        <br><br> 
                        <strong>Project Goal:</strong>
                        <br><br> 
                        The objective is to collect, process, and store audit data to facilitate non-compliance monitoring.
                        <br><br> 
                        <strong>Development Process:</strong>
                        <br><br> 
                        I used Python and GCP to perform API-based extraction, filtering completed audits and identifying non-conformities. The process was automated with Cloud Scheduler and stored in Cloud Storage.
                        <br><br> 
                        <strong>Conclusion:</strong>
                        <br><br> 
                        The project improved my automation and API integration skills. Future plans include optimizing data flow and expanding functionalities.
                    </p>
                    <a href="https://github.com/Tudolin/ChecklistFacilETL" target="_blank" class="project-link">View Code</a>
                </div>
            </div>
        
            <div class="project" data-aos="fade-up">
                <div class="project-info">
                    <h3 class="project-title">Web Application - RPG System</h3>
                    <p>
                        <strong>Introduction:</strong>
                        <br><br> 
                        The idea came from a hobby and the difficulty of finding an online RPG system that matched my vision.
                        <br><br> 
                        <strong>Project Goal:</strong>
                        <br><br> 
                        The goal was to build a web application focused on hosting online RPG sessions, character creation, and skill systems.
                        <br><br> 
                        <strong>Development Process:</strong>
                        <br><br> 
                        Development required Flask application routes, MongoDB Atlas for storing class, enemy, and skill information, GCP for VM hosting and Cloud Storage for player files, websockets for real-time event updates, and JavaScript for backend communication.
                        <br><br> 
                        <strong>Conclusion:</strong>
                        <br><br> 
                        This project was a significant challenge that involved constant learning about FrontEnd, sockets, sessions, data manipulation, SSL, and NGINX. I'm extremely happy to have made it functional.
                        <br><br>
                        <strong>Test Access: </strong>
                        If you'd like to test the site, create your character and join a session, here are test credentials.
                        <br>
                        <strong>Login: </strong>test
                        <strong>Password: </strong>test
                    </p>
                    <a href="https://familyrpg.servebeer.com/" target="_blank" class="project-link">View Application</a>
                </div>
            </div>
        </section>        
        <section id="about" class="section about" data-aos="fade-up">
            <h2 class="section-title">About <span>.</span></h2>
            <p>Currently working at WPP Media Services as a Data Engineer</p>
            <p>Graduated in Systems Analysis, currently working as a Data Engineer focused on evolving and specializing in Cloud Data Engineering.</p>
            <p>ðŸ’¼ Tools: Python, SQL, GCP, PySpark, Docker, MySQL, MongoDB, Flask, Pandas, GitHub Actions.</p>
            <p>ðŸ§³ Skills: Data processing, Rest API, Code versioning (Git), CI/CD, Cloud computing, Linux.</p>
        </section>
        <section id="experience" class="section experiences" data-aos="fade-up">
            <h2 class="section-title">Experience <span>.</span></h2>
        
            <div class="experience">
                <div class="experience-info">
                    <h3 class="experience-title">
                        <a target="_blank" href="https://www.mirumagency.com.br/">
                            <img align="right" height="94px" width="94px" alt="Mirum" src="https://media.licdn.com/dms/image/C560BAQGyA1CtAMmQbg/company-logo_200_200/0/1630594517323/mirumsoutheurope_logo?e=2147483647&v=beta&t=AHQFHqerzaF5RYfu3vkuxNeJf66bGXAydFRqw7Aaolw"/>
                        </a>
                        Mirum Agency - Data Engineering Intern
                    </h3>
                    <h4 class="duration">2023</h4>
                    <p>
                        During my internship at Mirum Agency, I worked on:
                        <br><br>
                        - Maintenance and interpretation of codes used in ETL/ELT processes
                        <br>
                        - Configuration and maintenance of Google Cloud Platform (GCP) services
                        <br>
                        - SQL query development and BI team support
                        <br>
                        - Python endpoint creation for media API integration (TikTok, Twitter, Pinterest, Google Ads)
                        <br>
                        - Client technical support including account configuration and service monitoring
                    </p>
                </div>
            </div>
        
            <div class="experience" data-aos="fade-up">
                <div class="experience-info">
                    <h3 class="experience-title">
                        <a target="_blank" href="https://safe7consultoria.com.br">
                            <img align="right" height="94px" width="94px" alt="Safe7" src="https://safe7consultoria.com.br/wp-content/uploads/2020/03/logo-nova-1024x1024.png"/>
                        </a>
                        Safe7 - Junior Data Engineer
                    </h3>
                    <h4 class="duration">2024</h4>
                    <p>
                        As a Junior Data Engineer at Safe7, my main responsibilities included:
                        <br><br>
                        - Business context analysis and solution development to maximize team productivity
                        <br>
                        - Database restructuring and modeling for greater efficiency
                        <br>
                        - Development of internal web tool "Safe7 Toolkit" centralizing processes
                        <br>
                        - ETL pipeline creation using GCP services with Python, web scraping and REST APIs
                    </p>
                </div>
            </div>

            <div class="experience" data-aos="fade-up">
                <div class="experience-info">
                    <h3 class="experience-title">
                        <a target="_blank" href="https://www.linkedin.com/company/wpp-media-services">
                            <img align="right" height="94px" width="94px" alt="WPP" src="https://media.licdn.com/dms/image/v2/D4D0BAQFXOWXbO-XlhA/company-logo_200_200/company-logo_200_200/0/1721999015833/wpp_media_services_logo?e=2147483647&v=beta&t=knUP6R_bgcfQvrr2m6cRqjAYZHJMV1xKK-QWCb9ZAcA"/>
                        </a>
                        WPP Media Services - Data Engineer
                    </h3>
                    <h4 class="duration">2024 - Present</h4>
                    <p>
                        As a Data Engineer at WPP Media Services, my responsibilities include:
                        <br><br>
                        - Developing and optimizing data pipelines in cloud environments (GCP)
                        <br>
                        - Automating data ingestion, transformation and storage processes (ETL/ELT)
                        <br>
                        - Monitoring and performing preventive maintenance on pipelines
                        <br>
                        - Collaborating with cross-functional teams to implement data-driven solutions
                    </p>
                </div>
            </div>
        </section>
        
        <section id="contact" class="section contact" data-aos="fade-up">
            <h2 class="section-title">Contact <span>.</span></h2>
            <p>Reach me via email: rafael.nadalin@outlook.com</p>
            <p>or Phone: +55 (41) 98413-5989</p>
            <button class="btn btn-outline-info"><a
                    href="/cv-rafael-nadalin.pdf" target="_blank"
                    class="footer-link"
                    style="text-decoration: none; color: white;">Download Resume</a></button>
        </section>
    </div>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>
    <script
        src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js">
    </script>
    <script
        src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js">
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/aos/2.3.4/aos.js">
    </script>
    <script>
        AOS.init({
            duration: 1000,
            easing: 'ease-in-out',
            once: true
        });
    </script>
</body>
</html>
